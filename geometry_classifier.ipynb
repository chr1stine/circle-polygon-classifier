{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "geometry-classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-JGc3zyV1zMz",
        "FwqVWKQW11PR",
        "g9uN9ubiw363",
        "gQTWmbX8xHXC",
        "3-n5qp9GyWX6",
        "MFw8pYgxxV_H",
        "zJ8V9CRcxe1b",
        "8GuoE0jDxoWr",
        "nr_j1FXCyk9i",
        "4vK8bf3C0FfU",
        "puE8hw5M0JNL"
      ],
      "authorship_tag": "ABX9TyPnxQ7zu1n3zrg9Nyredycs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chr1stine/circle-polygon-classifier/blob/master/geometry_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwlP5ErTyJcQ"
      },
      "source": [
        "# Генерирование данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1LuE7E9vX2E",
        "outputId": "6ef4748b-d434-4b9c-eb2c-1ac7cfc5153d"
      },
      "source": [
        "import matplotlib\n",
        "import numpy\n",
        "import cv2\n",
        "import pickle\n",
        "import pandas\n",
        "import torch\n",
        "import torchvision\n",
        "import PIL\n",
        "\n",
        "print('matplotlib '+matplotlib.__version__)\n",
        "print('numpy '+numpy.__version__)\n",
        "print('cv2 '+cv2.__version__)\n",
        "print('pandas '+pandas.__version__)\n",
        "print('torch '+torch.__version__)\n",
        "print('torchvision '+torchvision.__version__)\n",
        "print('PIL '+PIL.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "matplotlib 3.2.2\n",
            "numpy 1.19.5\n",
            "cv2 4.1.2\n",
            "pandas 1.1.5\n",
            "torch 1.8.1+cu101\n",
            "torchvision 0.9.1+cu101\n",
            "PIL 7.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO8_YC4ZxBQ6"
      },
      "source": [
        "## Генерация картинок для датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb6pZyuBve_g"
      },
      "source": [
        "n = 4000 # кол-во картинок для каждого класса\n",
        "img_size = 128 # размер каждой картинки"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JGc3zyV1zMz"
      },
      "source": [
        "### Круги"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZSVeMwWvhV_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from numpy import random\n",
        "import os\n",
        "\n",
        "# создать папку если такой нет\n",
        "directory = './figures/circles'\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "#параметры - координаты, радиус\n",
        "def gen_circle(i):\n",
        "    fig = plt.figure(figsize=(5, 5), dpi=100)\n",
        "\n",
        "    plt.xlim(0,5)\n",
        "    plt.ylim(0,5)\n",
        "\n",
        "    c = (random.rand()*4+1,random.rand()*4+1)\n",
        "    r = random.rand()*min(c[0],c[1],5-c[0],5-c[1])+random.rand()\n",
        "    circle = plt.Circle(c, radius=r)\n",
        "    fig.gca().add_patch(circle)\n",
        "    fig.gca().set_axis_off()\n",
        "    plt.savefig('./figures/circles/circle'+str(i)+'.png',bbox_inches='tight',pad_inches=0)\n",
        "    plt.close()\n",
        "    \n",
        "for i in range(n):\n",
        "    gen_circle(i)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwqVWKQW11PR"
      },
      "source": [
        "### Квадраты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELqf4zaRwMuD"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from numpy import random\n",
        "import os\n",
        "\n",
        "# создать папку если такой нет\n",
        "directory = './figures/polygons'\n",
        "if not os.path.exists(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "def gen_square(i):\n",
        "    fig = plt.figure(figsize=(5, 5), dpi=100)\n",
        "    \n",
        "    x0 = random.rand()*4\n",
        "    y0 = random.rand()*4\n",
        "    a = random.rand()*3\n",
        "    \n",
        "    plt.xlim(0,5)\n",
        "    plt.ylim(0,5)\n",
        "    \n",
        "    points = []\n",
        "    \n",
        "    x = x0-a/2.\n",
        "    y = y0-a/2\n",
        "    points.append((x,y))\n",
        "    \n",
        "    x = x0-a/2.\n",
        "    y = y0+a/2.\n",
        "    points.append((x,y))\n",
        "    \n",
        "    x = x0+a/2.\n",
        "    y = y0+a/2.\n",
        "    points.append((x,y))\n",
        "    \n",
        "    x = x0+a/2.\n",
        "    y = y0-a/2.\n",
        "    points.append((x,y))\n",
        "    \n",
        "    tetragon = plt.Polygon(points)\n",
        "    fig.gca().add_patch(tetragon)    \n",
        "    fig.gca().set_axis_off()\n",
        "    plt.savefig('figures/polygons/polygon'+str(i)+'.png',bbox_inches='tight',pad_inches=0)\n",
        "    plt.close()\n",
        "    \n",
        "    \n",
        "for i in range(n):\n",
        "    gen_square(i)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9uN9ubiw363"
      },
      "source": [
        "## Создание датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crxrge-1wy4w"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "file_list = []\n",
        "class_list = []\n",
        "\n",
        "folder = \"figures\"\n",
        "\n",
        "categories = [\"circles\", \"polygons\"]\n",
        "\n",
        "# Checking or all images in the data folder\n",
        "for category in categories :\n",
        "    path = os.path.join(folder, category)\n",
        "    for img in os.listdir(path):\n",
        "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# массив пар (картинка, класс)\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in categories :\n",
        "        path = os.path.join(folder, category)\n",
        "        class_num = categories.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try :\n",
        "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "                new_array = cv2.resize(img_array, (img_size, img_size))\n",
        "                training_data.append([new_array, class_num])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "# свойства\n",
        "X = []\n",
        "\n",
        "# ярлыки\n",
        "y = []\n",
        "\n",
        "# в features \"попадают\" сами картинки, в label - классы\n",
        "for features, label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "# из списка матриц пикселей картинки получаем матрицу списков пикселей картинок\n",
        "X = np.array(X).reshape(-1, img_size, img_size, 1)\n",
        "\n",
        "# сериализуем датасет в файл\n",
        "pickle_out = open(\"features.pickle\", \"wb\")\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"labels.pickle\", \"wb\")\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQTWmbX8xHXC"
      },
      "source": [
        "## Создание класса для датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAV71nNexPHy"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pickle\n",
        "\n",
        "class figures_dataset(Dataset):\n",
        "    def __init__(self):\n",
        "        features_fname = 'features.pickle'\n",
        "        labels_fname = 'labels.pickle'\n",
        "            \n",
        "        # десериализация картинок\n",
        "        f_pickle_in = open(features_fname,'rb')\n",
        "        self.images = pickle.load(f_pickle_in,encoding='bytes')\n",
        "        \n",
        "        # десериализация меток\n",
        "        l_pickle_in = open(labels_fname,'rb')\n",
        "        self.labels = pickle.load(l_pickle_in,encoding='bytes')\n",
        "        \n",
        "        # аугментация и зашумление картинок\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.GaussianBlur(11,11),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        self.noise = torch.rand(len(self.images),img_size,img_size,1)\n",
        "        \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # проверка, что индекс \"массивоподобный\"\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "            \n",
        "        # возвращение словаря <картинка,метка>\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "            \n",
        "        image = image + np.array(self.noise[idx])\n",
        "        image = self.transform(image)\n",
        "        sample = image, label\n",
        "\n",
        "        \n",
        "        return sample\n",
        "\n",
        "figures = figures_dataset()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-n5qp9GyWX6"
      },
      "source": [
        "# Обучение нейросети"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFw8pYgxxV_H"
      },
      "source": [
        "## Вызов DataLoader и объявление нейросети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbI8s494xamO"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from random import shuffle\n",
        "\n",
        "# деление датасета на обучающую и проверяющую выборки\n",
        "validation_split = .2\n",
        "figures_size = len(figures)\n",
        "indices = list(range(figures_size))\n",
        "shuffle(indices)\n",
        "split = int(np.floor(validation_split * figures_size))\n",
        "train_indices, test_indices = indices[split:], indices[:split]\n",
        "\n",
        "# перемешивает индексы\n",
        "test = SubsetRandomSampler(test_indices)\n",
        "train = SubsetRandomSampler(train_indices)\n",
        "\n",
        "# размер батча\n",
        "b_size=32\n",
        "\n",
        "test_set = DataLoader(figures, batch_size=b_size, sampler=test)\n",
        "train_set = DataLoader(figures, batch_size=b_size, sampler=train)\n",
        "\n",
        "\n",
        "# нейросеть\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "                \n",
        "        self.conv1 = nn.Conv2d(1, 3, 3)\n",
        "        self.conv2 = nn.Conv2d(3, 6, 3)\n",
        "        self.conv3 = nn.Conv2d(6,12,3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dout = nn.Dropout(0.2)\n",
        "        self.fc1 = nn.Linear(12 * 14 * 14, 2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.dout(self.pool(self.conv1(x)))\n",
        "        x = self.dout(self.pool(self.conv2(x)))\n",
        "        x = self.dout(self.pool(self.conv3(x)))\n",
        "        x = torch.flatten(x,1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "net = Net()\n",
        "\n",
        "# loss-функция\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ8V9CRcxe1b"
      },
      "source": [
        "## Запуск обучения и вывод графика loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "id": "TY3pChirxj8T",
        "outputId": "1967e091-a761-44b3-f6cd-455e4207ff32"
      },
      "source": [
        "epochs = 15\n",
        "loss_vals = []\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0.0 # для вывода по каждым freq мини-батчам\n",
        "    loss_val = 0.0 # для вывода общего loss по эпохе\n",
        "    for i, data in enumerate(train_set, 0):\n",
        "\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # вывод loss\n",
        "        running_loss += loss.item()\n",
        "        loss_val = loss_val+running_loss\n",
        "        freq = 200  # каждые freq мини-батчей\n",
        "        if i % freq == freq-1:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / freq))\n",
        "            running_loss = 0.0\n",
        "    \n",
        "    loss_vals.append(loss_val/(b_size*len(train_set)))\n",
        "\n",
        "plt.plot(range(epochs),loss_vals)\n",
        "plt.legend(['loss'])\n",
        "print('Finished Training')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py:132: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  img = torch.from_numpy(np.array(pic, np.float32, copy=False))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   200] loss: 0.694\n",
            "[2,   200] loss: 0.685\n",
            "[3,   200] loss: 0.673\n",
            "[4,   200] loss: 0.657\n",
            "[5,   200] loss: 0.632\n",
            "[6,   200] loss: 0.560\n",
            "[7,   200] loss: 0.484\n",
            "[8,   200] loss: 0.399\n",
            "[9,   200] loss: 0.352\n",
            "[10,   200] loss: 0.343\n",
            "[11,   200] loss: 0.327\n",
            "[12,   200] loss: 0.302\n",
            "[13,   200] loss: 0.289\n",
            "[14,   200] loss: 0.291\n",
            "[15,   200] loss: 0.265\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GuoE0jDxoWr"
      },
      "source": [
        "## Измерение качества"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A41_mc8Bxsa7",
        "outputId": "d16661de-e6bd-4f0d-c482-84786671effb"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_set:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Точность нейросети на тестовой выборке: %d %%' % (100 * correct / total))\n",
        "\n",
        "\n",
        "class_correct = list(0. for i in range(2))\n",
        "class_total = list(0. for i in range(2))\n",
        "with torch.no_grad():\n",
        "    for data in test_set:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(b_size):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "classes = ['кругов','квадратов']\n",
        "for i in range(2):\n",
        "    print('Точность %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Точность нейросети на тестовой выборке: 81 %\n",
            "Точность кругов : 95 %\n",
            "Точность квадратов : 67 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr_j1FXCyk9i"
      },
      "source": [
        "# Тест на одной картинке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vK8bf3C0FfU"
      },
      "source": [
        "## На случайной из тестового датасета"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pEvl5vMyp4C"
      },
      "source": [
        "# выбор случайного батча\n",
        "data = next(iter(test_set))\n",
        "\n",
        "# отсечение первой картинки из выбранного батча\n",
        "img, label = data[0][0],[0]\n",
        "img1 = img.squeeze(0)\n",
        "plt.imshow(img1)\n",
        "plt.show()\n",
        "\n",
        "# определение отклика\n",
        "image = data[0][:1]\n",
        "outputs = net(image)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "print('prediction: ',classes[predicted[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puE8hw5M0JNL"
      },
      "source": [
        "## На конкретном файле"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdRUfPl-0OXJ"
      },
      "source": [
        "# указание файла с тестовой картинкой\n",
        "fname = './figures/polygons/polygon6.png'\n",
        "\n",
        "# считывание, перевод в массив\n",
        "img_array = cv2.imread(os.path.join('.', fname), cv2.IMREAD_GRAYSCALE)# чтение картинки в чб\n",
        "new_array = cv2.resize(img_array, (img_size, img_size))# масштабирование картинки под нейронку\n",
        "X = []\n",
        "for features in new_array:\n",
        "    X.append(features)\n",
        "X = np.array(X).reshape(1, 1, img_size, img_size)\n",
        "\n",
        "# получение отклика\n",
        "outputs = net(torch.Tensor(X[:1]))\n",
        "_, predicted = torch.max(outputs,1)\n",
        "classes = ['круг','квадрат']\n",
        "print(classes[predicted[0]])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}